{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Null accuracy, handling missing values\n",
    "2. Confusion matrix, sensitivity, specificity, setting a threshold\n",
    "3. Handling categorical features, interpreting logistic regression coefficients\n",
    "4. Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Null Accuracy, Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap of the Titanic exercise"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668161434978\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# TASK 1: read the data from titanic.csv into a DataFrame\n",
    "import pandas as pd\n",
    "titanic = pd.read_csv('../../data/titanic.csv', index_col='PassengerId')\n",
    "\n",
    "# TASK 2: define Pclass/Parch as the features and Survived as the response\n",
    "feature_cols = ['Pclass', 'Parch']\n",
    "X = titanic[feature_cols]\n",
    "y = titanic.Survived\n",
    "\n",
    "# TASK 3: split the data into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# TASK 4: fit a logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# TASK 5: make predictions on testing set and calculate accuracy\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null accuracy\n",
    "\n",
    "Null accuracy is the accuracy that could be achieved by always predicting the **most frequent class**. It is a baseline against which you may want to measure your classifier."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42600896861\n",
      "0.57399103139\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# compute null accuracy manually\n",
    "print y_test.mean()\n",
    "print 1 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57399103139\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# equivalent function in scikit-learn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dumb = DummyClassifier(strategy='most_frequent')\n",
    "dumb.fit(X_train, y_train)\n",
    "y_dumb_class = dumb.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_dumb_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "scikit-learn models expect that all values are **numeric** and **hold meaning**. Thus, missing values are not allowed by scikit-learn.\n",
    "\n",
    "One possible strategy is to just **drop missing values**:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "titanic.isnull().sum()\n",
    "#titanic"
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "titanic.isnull().sum()"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# drop rows with any missing values\n",
    "titanic.dropna().shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# drop rows where Age is missing\n",
    "titanic[titanic.Age.notnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes a better strategy is to **impute missing values**:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill missing values for Age with the mean age\n",
<<<<<<< HEAD
    "#impute - using other x values to infer age\n",
=======
>>>>>>> upstream/master
    "titanic.Age.fillna(titanic.Age.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId\n",
      "1      22.000000\n",
      "2      38.000000\n",
      "3      26.000000\n",
      "4      35.000000\n",
      "5      35.000000\n",
      "6      29.699118\n",
      "7      54.000000\n",
      "8       2.000000\n",
      "9      27.000000\n",
      "10     14.000000\n",
      "11      4.000000\n",
      "12     58.000000\n",
      "13     20.000000\n",
      "14     39.000000\n",
      "15     14.000000\n",
      "16     55.000000\n",
      "17      2.000000\n",
      "18     29.699118\n",
      "19     31.000000\n",
      "20     29.699118\n",
      "21     35.000000\n",
      "22     34.000000\n",
      "23     15.000000\n",
      "24     28.000000\n",
      "25      8.000000\n",
      "26     38.000000\n",
      "27     29.699118\n",
      "28     19.000000\n",
      "29     29.699118\n",
      "30     29.699118\n",
      "         ...    \n",
      "862    21.000000\n",
      "863    48.000000\n",
      "864    29.699118\n",
      "865    24.000000\n",
      "866    42.000000\n",
      "867    27.000000\n",
      "868    31.000000\n",
      "869    29.699118\n",
      "870     4.000000\n",
      "871    26.000000\n",
      "872    47.000000\n",
      "873    33.000000\n",
      "874    47.000000\n",
      "875    28.000000\n",
      "876    15.000000\n",
      "877    20.000000\n",
      "878    19.000000\n",
      "879    29.699118\n",
      "880    56.000000\n",
      "881    25.000000\n",
      "882    33.000000\n",
      "883    22.000000\n",
      "884    28.000000\n",
      "885    25.000000\n",
      "886    39.000000\n",
      "887    27.000000\n",
      "888    19.000000\n",
      "889    29.699118\n",
      "890    26.000000\n",
      "891    32.000000\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# equivalent function in scikit-learn, supports mean/median/most_frequent\n",
    "#imputer is a nice function to use\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(strategy='mean', axis=1)\n",
    "#array area fixed\n",
    "titanic['Age'] = imp.fit_transform(titanic.Age.reshape(1,-1)).T\n",
    "print titanic.Age\n"
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# equivalent function in scikit-learn, supports mean/median/most_frequent\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(strategy='mean', axis=1)\n",
    "titanic['Age'] = imp.fit_transform(titanic.Age).T"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67264573991\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# include Age as a feature\n",
    "feature_cols = ['Pclass', 'Parch', 'Age']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[107,  21],\n",
       "       [ 52,  43]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45263157894736844"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# calculate the sensitivity\n",
    "43 / float(52 + 43)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8359375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# calculate the specificity\n",
    "107 / float(107 + 21)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store the predicted probabilities\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1168cf650>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEPCAYAAABCyrPIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2LzqjgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1040cf890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# plot the predicted probabilities\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y_pred_prob)\n",
    "plt.xlabel('Predicted probability of survival')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0 1 0 1 1 1 0 0 0 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0 0 1 1\n",
      " 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0\n",
      " 0 1 1 0 1 1 0 1 0 0 1 0 0 0 1 1 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 0 1 0 1\n",
      " 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 0\n",
      " 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 1\n",
      " 1 0 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "# change the threshold for predicting survived to increase sensitivity\n",
    "import numpy as np\n",
    "y_pred_class = np.where(y_pred_prob > 0.25, 1, 0)\n",
    "print y_pred_class"
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change the threshold for predicting survived to increase sensitivity\n",
    "import numpy as np\n",
    "y_pred_class = np.where(y_pred_prob > 0.25, 1, 0)"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  0.  0.  1.  1.  0.  1.  1.  0.\n",
      "   0.  1.  0.  0.  1.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.\n",
      "   1.  0.  1.  1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "   0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.  0.  1.\n",
      "   1.  0.  0.  1.  1.  0.  1.  1.  0.  1.  0.  0.  1.  0.  0.  0.  1.  1.\n",
      "   1.  0.  0.  0.  0.  1.  0.  0.  1.  0.  1.  1.  0.  1.  1.  0.  0.  0.\n",
      "   1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  1.  1.  0.  1.  1.  1.\n",
      "   1.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  1.  0.  1.  0.  1.  0.\n",
      "   0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.\n",
      "   0.  1.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  1.  0.\n",
      "   1.  1.  1.  0.  1.  1.  0.  1.  0.  1.  1.  1.  0.  1.  1.  1.  1.  1.\n",
      "   0.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  0.  1.  1.  0.\n",
      "   0.  1.  1.  1.  1.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# equivalent function in scikit-learn\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize(y_pred_prob.reshape(1,-1), 0.25)\n",
    "print y_pred_class"
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# equivalent function in scikit-learn\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class = binarize(y_pred_prob, 0.25)"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57 71]\n",
      " [27 68]]\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# new confusion matrix\n",
    "print metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715789473684\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# new sensitivity\n",
    "print 68 / float(27 + 68)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4453125\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# new specificity\n",
    "print 57 / float(57 + 71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Handling Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn expects all features to be numeric. So how do we include a categorical feature in our model?\n",
    "\n",
    "- **Ordered categories:** transform them to sensible numeric values (example: small=1, medium=2, large=3)\n",
    "- **Unordered categories:** use dummy encoding\n",
    "\n",
    "**Pclass** is an ordered categorical feature, and is already encoded as 1/2/3, so we leave it as-is.\n",
    "\n",
    "**Sex** is an unordered categorical feature, and needs to be dummy encoded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy encoding with two levels"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode Sex_Female feature\n",
    "titanic['Sex_Female'] = titanic.Sex.map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# include Sex_Female in the model\n",
    "feature_cols = ['Pclass', 'Parch', 'Age', 'Sex_Female']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg=LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression coefficients"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', -1.220932091967994),\n",
       " ('Parch', -0.11739489104090838),\n",
       " ('Age', -0.040484280706099898),\n",
       " ('Sex_Female', 2.6815252122851363)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "zip(feature_cols, logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\log \\left({p\\over 1-p}\\right) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3 + \\beta_4x_4$$"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', 0.2949551134641889),\n",
       " ('Parch', 0.88923397329186071),\n",
       " ('Age', 0.96032426001204996),\n",
       " ('Sex_Female', 14.607355632434441)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# convert log-odds to odds\n",
    "zip(feature_cols, np.exp(logreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probability of survival for **Adam**: first class, no parents or kids, 29 years old, male."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LouisTsang/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.50359582])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba([1, 0, 29, 0])[:,1]"
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg.predict_proba([1, 0, 29, 0])[:, 1]"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Pclass coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probability of survival for **Bill**: same as Adam, except second class."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LouisTsang/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.23031231])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba([2, 0, 29, 0])[:,1]"
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logreg.predict_proba([2, 0, 29, 0])[:, 1]"
>>>>>>> upstream/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could we have calculated that change ourselves using the coefficients?\n",
    "\n",
    "$$odds = \\frac {probability} {1 - probability}$$\n",
    "\n",
    "$$probability = \\frac {odds} {1 + odds}$$"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2277992277992278"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# convert Adam's probability to odds\n",
    "adamodds = 0.5/(1 - 0.5)\n",
    "\n",
    "# adjust odds for Bill due to lower class\n",
    "billodds = adamodds * 0.295\n",
    "\n",
    "# convert Bill's odds to probability\n",
    "billodds/(1 + billodds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Sex_Female coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict probability of survival for **Susan**: same as Adam, except female."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/LouisTsang/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.9367848])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "logreg.predict_proba([1, 0, 29, 1])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate that change ourselves:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9358974358974359"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# adjust odds for Susan due to her sex\n",
    "susanodds = adamodds * 14.6\n",
    "\n",
    "# convert Susan's odds to probability\n",
    "susanodds/(1 + susanodds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we interpret the **Sex_Female coefficient**? For a given Pclass/Parch/Age, being female is associated with an increase in the **log-odds of survival** by 2.68 (or an increase in the **odds of survival** by 14.6) as compared to a male, which is called the **baseline level**.\n",
    "\n",
    "What if we had reversed the encoding for Sex?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 110,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# encode Sex_Male feature\n",
    "titanic['Sex_Male'] = titanic.Sex.map({'male':1, 'female':0})"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', -1.2201766590223218),\n",
       " ('Parch', -0.11678128455936061),\n",
       " ('Age', -0.0404329886036527),\n",
       " ('Sex_Male', -2.6803868859152278)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# include Sex_Male in the model instead of Sex_Female\n",
    "feature_cols = ['Pclass', 'Parch', 'Age', 'Sex_Male']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg.fit(X_train, y_train)\n",
    "zip(feature_cols, logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficient is the same, except that it's **negative instead of positive**. As such, your choice of category for the baseline does not matter, all that changes is your **interpretation** of the coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy encoding with more than two levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we include an unordered categorical feature with more than two levels, like **Embarked**? We can't simply encode it as C=1, Q=2, S=3, because that would imply an **ordered relationship** in which Q is somehow \"double\" C and S is somehow \"triple\" C.\n",
    "\n",
    "Instead, we create **additional dummy variables**:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Embarked_C  Embarked_Q  Embarked_S\n",
       "PassengerId                                    \n",
       "1                     0           0           1\n",
       "2                     1           0           0\n",
       "3                     0           0           1\n",
       "4                     0           0           1\n",
       "5                     0           0           1\n",
       "6                     0           1           0\n",
       "7                     0           0           1\n",
       "8                     0           0           1\n",
       "9                     0           0           1\n",
       "10                    1           0           0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# create 3 dummy variables\n",
    "pd.get_dummies(titanic.Embarked, prefix='Embarked').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we actually only need **two dummy variables, not three**. Why? Because two dummies captures all of the \"information\" about the Embarked feature, and implicitly defines C as the **baseline level**."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Embarked_Q  Embarked_S\n",
       "PassengerId                        \n",
       "1                     0           1\n",
       "2                     0           0\n",
       "3                     0           1\n",
       "4                     0           1\n",
       "5                     0           1\n",
       "6                     1           0\n",
       "7                     0           1\n",
       "8                     0           1\n",
       "9                     0           1\n",
       "10                    0           0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# create 3 dummy variables, then exclude the first\n",
    "pd.get_dummies(titanic.Embarked, prefix='Embarked').iloc[:, 1:].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we interpret the encoding:\n",
    "\n",
    "- C is encoded as Embarked_Q=0 and Embarked_S=0\n",
    "- Q is encoded as Embarked_Q=1 and Embarked_S=0\n",
    "- S is encoded as Embarked_Q=0 and Embarked_S=1\n",
    "\n",
    "If this is confusing, think about why we only needed one dummy variable for Sex (Sex_Female), not two dummy variables (Sex_Female and Sex_Male). In general, if you have a categorical feature with **k levels**, you create **k-1 dummy variables**."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 114,
=======
   "execution_count": null,
>>>>>>> upstream/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame with the two dummy variable columns\n",
    "embarked_dummies = pd.get_dummies(titanic.Embarked, prefix='Embarked').iloc[:, 1:]\n",
    "\n",
    "# concatenate the original DataFrame and the dummy DataFrame (axis=0 means rows, axis=1 means columns)\n",
    "titanic = pd.concat([titanic, embarked_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_Female</th>\n",
       "      <th>Age_imp</th>\n",
       "      <th>Sex_Male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex  Age  \\\n",
       "PassengerId                                                                   \n",
       "1                                      Braund, Mr. Owen Harris    male   22   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38   \n",
       "3                                       Heikkinen, Miss. Laina  female   26   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35   \n",
       "5                                     Allen, Mr. William Henry    male   35   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \\\n",
       "PassengerId                                                           \n",
       "1                1      0         A/5 21171   7.2500   NaN        S   \n",
       "2                1      0          PC 17599  71.2833   C85        C   \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S   \n",
       "4                1      0            113803  53.1000  C123        S   \n",
       "5                0      0            373450   8.0500   NaN        S   \n",
       "\n",
       "             Sex_Female  Age_imp  Sex_Male  Embarked_Q  Embarked_S  \n",
       "PassengerId                                                         \n",
       "1                     0       22         1           0           1  \n",
       "2                     1       38         0           0           0  \n",
       "3                     1       26         0           0           1  \n",
       "4                     1       35         0           0           1  \n",
       "5                     0       35         1           0           1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pclass', -1.1884985998346915),\n",
       " ('Parch', -0.09362239042482598),\n",
       " ('Age', -0.040727318327547543),\n",
       " ('Sex_Female', 2.6425066172546092),\n",
       " ('Embarked_Q', -0.18494080723338657),\n",
       " ('Embarked_S', -0.61019904879175724)]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "# include Embarked_Q and Embarked_S in the model\n",
    "feature_cols = ['Pclass', 'Parch', 'Age', 'Sex_Female', 'Embarked_Q', 'Embarked_S']\n",
    "X = titanic[feature_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "logreg=LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train, y_train)\n",
    "zip(feature_cols, logreg.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.77777778  0.8         0.7752809   0.86516854  0.7752809   0.7752809\n",
      "  0.78651685  0.7752809   0.80898876  0.81818182]\n",
      "0.795775734877\n"
     ]
    }
   ],
=======
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
>>>>>>> upstream/master
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# evaluate the model using 10-fold cross-validation\n",
<<<<<<< HEAD
    "#this line is only scoring accuracy - a accuracy score is produced on each partition\n",
=======
>>>>>>> upstream/master
    "scores = cross_val_score(LogisticRegression(), X, y, scoring='accuracy', cv=10)\n",
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Evaluate each stage of the model with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Evaluate the Cross-Validation score with different values of n (2, 5, 10, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
<<<<<<< HEAD
   "version": "2.7.11"
=======
   "version": "2.7.10"
>>>>>>> upstream/master
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
