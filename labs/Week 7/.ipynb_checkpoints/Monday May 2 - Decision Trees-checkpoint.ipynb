{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Regression Trees\n",
    "\n",
    "## Wednesday May 5, 2016\n",
    "\n",
    "### Classification\n",
    "\n",
    "'''\n",
    "\n",
    "Classification and Regression Trees\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Classification and Regression Trees\n",
    "\n",
    "'''\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Read, Explore, and Process data\n",
    "'''\n",
    "\n",
    "# Read in the data\n",
    "titanic = pd.read_csv('../../data/titanic.csv')\n",
    "\n",
    "# Take a  selection of the variables\n",
    "d = titanic[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values in all columns\n",
    "d.isnull().sum()\n",
    "d.groupby(['Sex', 'Pclass']).Age.apply(lambda x: x.isnull().sum()) / d.groupby(['Sex', 'Pclass']).Age.count()\n",
    "\n",
    "# Convert all variables to numeric so for scikit learn\n",
    "d['Sex'] = np.where(d.Sex == 'female', 1, 0)\n",
    "\n",
    "# Fill in missing values with the mean value (hint: use .fillna())\n",
    "d['Age'] = d['Age'].fillna(d['Age'].mean())\n",
    "\n",
    "# Explore the data to identify trends in characteristics of survivors\n",
    "d.Survived.value_counts()                    # How many people lived and died\n",
    "d.Survived.mean()                            # The survival rate for everyone\n",
    "d.groupby('Sex').Survived.mean()             # By Sex: women have higher survival rates\n",
    "d.groupby('Pclass').Survived.mean()          # By Pclass: 1st class passengers have higher survival rates\n",
    "d.groupby(['Sex', 'Pclass']).Survived.mean() # By Sex and Pclass: Women in the 1st and 2nd classes had the highest survival rates\n",
    "\n",
    "# Create a proxy variable representing whether the Spouse was on board\n",
    "d['Spouse'] = ((d.Age > 18) & (d.SibSp >= 1)).astype(int)\n",
    "d.Spouse.value_counts()\n",
    "d.groupby(['Pclass', 'Spouse']).Survived.mean() # Having a spouse appears to increase survival in the 1st class only\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Split into training and test datasets, and build the model\n",
    "\n",
    "'''\n",
    "\n",
    "survived = d['Survived']\n",
    "del d['Survived']\n",
    "\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(d,survived, random_state=1)\n",
    "\n",
    "# Create a decision tree classifier instance (start out with a small tree for interpretability)\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# Fit the decision tree classifier\n",
    "ctree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Create a feature vector\n",
    "features = d.columns.tolist()\n",
    "\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How to interpret the diagram?\n",
    "ctree.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict what will happen for 1st class woman\n",
    "#features\n",
    "ctree.predict_proba([1, 1, 25, 0, 0, 0])\n",
    "ctree.predict([1, 1, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predict what will happen for a 3rd class man\n",
    "ctree.predict_proba([3, 0, 25, 0, 0, 0])\n",
    "ctree.predict([3, 0, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from StringIO import StringIO\n",
    "out = StringIO()\n",
    "tree.export_graphviz(ctree, out_file = out)\n",
    "# OUTPUT DOT LANGUAGE SCRIPTS\n",
    "print out.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(ctree, out_file='tree_vehicles.dot', feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pydot\n",
    "# make sure pydot and graphviz are installed \n",
    "# if problems see here:\n",
    "# http://stackoverflow.com/questions/15951748/pydot-and-graphviz-error-couldnt-import-dot-parser-loading-of-dot-files-will/17902926#17902926\n",
    "\n",
    "dot_data = StringIO()  \n",
    "tree.export_graphviz(\n",
    "    ctree, \n",
    "    out_file=dot_data,\n",
    "    feature_names=features,  \n",
    "    class_names=[\"died\",\"survived\"],  \n",
    "    filled=True, \n",
    "    rounded=True,  \n",
    "    special_characters=True\n",
    ")  \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Which features are the most important?\n",
    "ctree.feature_importances_\n",
    "\n",
    "# Clean up the output\n",
    "pd.DataFrame(zip(features, ctree.feature_importances_)).sort_index(by=1, ascending=False)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = ctree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "metrics.accuracy_score(y_test, preds)\n",
    "\n",
    "# Confusion matrix\n",
    "pd.crosstab(y_test, preds, rownames=['actual'], colnames=['predicted'])\n",
    "\n",
    "# Make predictions on the test set using predict_proba\n",
    "probs = ctree.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculate the AUC metric\n",
    "metrics.roc_auc_score(y_test, probs)\n",
    "\n",
    "# Decision Trees have notorouisly high variance, so what can we do\n",
    "# to better estimate the out of sample error of a high variance model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# compare AUC using cross-validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "cross_val_score(ctree, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "\n",
    "# so far logistic regression is winning..\n",
    "\n",
    "'''\n",
    "\n",
    "FINE-TUNING THE TREE\n",
    "\n",
    "'''\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\n",
    "# check CV score for max depth = 3\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))\n",
    "\n",
    "# check CV score for max depth = 10\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=10)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Conduct a grid search for the best tree depth\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1)\n",
    "depth_range = range(1, 20)\n",
    "param_grid = dict(max_depth=depth_range)\n",
    "grid = GridSearchCV(ctree, param_grid, cv=5, scoring='roc_auc')\n",
    "grid.fit(d, survived)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check out the scores of the grid search\n",
    "grid_mean_scores = [result[1] for result in grid.grid_scores_]\n",
    "\n",
    "\n",
    "# Plot the results of the grid search\n",
    "plt.figure()\n",
    "plt.plot(depth_range, grid_mean_scores)\n",
    "plt.hold(True)\n",
    "plt.grid(True)\n",
    "plt.plot(grid.best_params_['max_depth'], grid.best_score_, 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the best estimator\n",
    "best = grid.best_estimator_\n",
    "\n",
    "cross_val_score(best, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "\n",
    "# Still not as good as Logistic Regression.. \n",
    "# Let's try something else\n",
    "\n",
    "\n",
    "\n",
    "### EXERCISE ###\n",
    "''' Use Grid Search try scan over three parameters\n",
    "1. max_depth:     from 1 to 20\n",
    "2. criterion:     (either 'gini' or 'entropy')\n",
    "3. max_features : range (1,5)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision trees (like many other classification models)\n",
    "# can also be used for regression!\n",
    "\n",
    "\n",
    "drinks = pd.read_csv('../../data/drinks.csv', na_filter=False)\n",
    "\n",
    "drinks\n",
    "\n",
    "# Make dummy columns for each of the 6 regions\n",
    "for continent_ in ['AS', 'NA', 'EU', 'AF', 'SA', 'OC']:\n",
    "    drinks[continent_] = drinks['continent'] == continent_\n",
    "\n",
    "drinks\n",
    "\n",
    "\n",
    "del drinks['continent']\n",
    "del drinks['country']\n",
    "del drinks['total_litres_of_pure_alcohol'] # this doesn't seem fair does it?\n",
    "\n",
    "X = drinks.drop('wine_servings', axis=1)\n",
    "y = drinks['wine_servings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "\n",
    "rtree = tree.DecisionTreeRegressor()\n",
    "\n",
    "rtree.fit(X_train, y_train)\n",
    "rtree.predict(X_test)\n",
    "\n",
    "scores = cross_val_score(rtree, X, y, cv=10, scoring='mean_squared_error')\n",
    "mse_scores = -scores\n",
    "mse_scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores\n",
    "rmse_scores.mean()\n",
    "\n",
    "wine_mean = y.mean()\n",
    "wine_mean\n",
    "\n",
    "features = X.columns\n",
    "pd.DataFrame(zip(features, rtree.feature_importances_)).sort_index(by=1, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
