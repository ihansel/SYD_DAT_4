{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYD DAT 3 Lab 1 - Git and Markdown\n",
    "\n",
    "##Homework:\n",
    "\n",
    "#### Setup\n",
    "* Resolve any installation issues before next class.\n",
    "* Make sure you have a github profile and created a repo called \"SYD_DAT_4\"\n",
    "* Clone the class repo (this one!)\n",
    "* Review this [code](../labs/Week 1/00_python_refresher.py) for a recap of some Python basics.\n",
    "\n",
    "#### Communication\n",
    "* Read [Analyzing the Analyzers](http://cdn.oreillystatic.com/oreilly/radarreport/0636920029014/Analyzing_the_Analyzers.pdf) for a useful look at the different types of data scientists. Write down 5 key points you took away from the article\n",
    "\n",
    "My observations from reading the text above include the following;\n",
    "    * There is quite a bunch of hype about data scientists and because of this, data scientist might be mistakenly seen as miracle workers.\n",
    "    * Data Scientists can be categorised into four different skill sets which include;\n",
    "        * Data Researchers\n",
    "        * Data Creatives\n",
    "        * Data Developers\n",
    "        * Data Business People\n",
    "    * The categories above are based on different distribution of skillsets like programming, math/operational research, statistics, machine learning/big data and business\n",
    "    * Having a broad skillset is very valuable for data scientists (T-shaped Data scientist).\n",
    "    * As data scientist is important to be to communicate your areas of depth because it helps others to know where your expertise lies.\n",
    "\n",
    "> Great summary Augustine. \n",
    "\n",
    "* Read about some [Markdown Techniques](http://daringfireball.net/projects/markdown/syntax)\n",
    "* Write a summary of 2 chapters of [The Data Science Handbook](http://www.thedatasciencehandbook.com/) in Markdown and submit a pull request in the Lab Directory\n",
    "\n",
    "Data science is a role that involves lots of collaboration and team work. It also requires a broad skill set which might include but is not limited to \n",
    "\n",
    "> Can you expand on this? Write about a paragraph for each chapter and re-submit.\n",
    "\n",
    "#### Programming\n",
    "* Complete the lab from class and the additional Exercise below\n",
    " #### Lab 1 solutions\n",
    "   * filter DataFrame to only include European countries\n",
    "     *  `drinks[drinks.continent == 'EU']`\n",
    "   * calculate the average 'beer_servings' for all of Europe\n",
    "      * `drinks.beer_servings[drinks.continent == 'EU'].mean()`\n",
    "   * determine which 10 countries have the highest total_litres_of_pure_alcohol\n",
    "      * `drinks.sort('total_litres_of_pure_alcohol', ascending=False).head(10)`\n",
    "   * rename the column 'beer_servings' to 'beer'\n",
    "      * `drinks.rename(columns={'beer_servings': 'beer'}, inplace=True)`\n",
    "   * add a new column as a function of existing columns, total_servings = beer + wine + spirits\n",
    "      * `drinks['total_servings'] = drinks.beer + drinks.wine_servings + drinks.spirit_servings`\n",
    "   * remove the column you just added\n",
    "      * `drinks.drop('total_servings', 1)`\n",
    "      \n",
    "\n",
    "#### Course Project\n",
    "* Come up with 5 different ideas for your course project. For each one list:\n",
    "  * Overview of your idea\n",
    "  * What data you will use\n",
    "  * What the outcome is that you are trying to achieve\n",
    "  * Any ideas of modelling techniques it may involve\n",
    "  \n",
    "  #### Course Project Ideas\n",
    "  * Analysing posts by people am following on twitter, to come with topics. The outcome is topics among which the different posts fall. I might probably use Support Vector Machines.\n",
    "> Interesting idea, that should be doable if you are comforatable with web scraping.\n",
    "\n",
    "  * Using github api to recommend projects that a user might be interested in based on what projects they star, what they regularly work on and who they follow. Not very sure what modelling technique i would use for this one\n",
    "> Great idea, would require a bit of text analysis I think  \n",
    "\n",
    "  * Predict the likelihood of a customer being satisfied or not using an annonymized data set from Santander bank, (i got this idea from kaggle competition - [Here](https://www.kaggle.com/c/santander-customer-satisfaction/data)). This sounds like a classification problem so i would probably use logistic regression.\n",
    "> This would be a good project\n",
    "\n",
    "  * Analysing my gmail inbox to find relationships between the emails that i read, reply to, archive or never read.\n",
    "> Interesting idea, should be achieveable with the Gmail API \n",
    " \n",
    "  * Using the australian weather data set to predict the weather, probably using logistic regression.\n",
    "> If you're interested in weather then this could be a good project as well. \n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework1_ian_hansel.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Four - Movie Lens Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#importing user data\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_table('../labs/Week 1/u.user', sep='|', header=None, names=user_cols)\n",
    "\n",
    "# for each occupation in 'users', count the number of occurrences\n",
    "users.groupby('occupation').count()\n",
    "\n",
    "# for each occupation, calculate the mean age\n",
    "users.groupby('occupation').age.mean()\n",
    "\n",
    "# for each occupation, calculate the minimum and maximum ages\n",
    "users.groupby('occupation').age.min() #min age\n",
    "users.groupby('occupation').age.max() #max age\n",
    "\n",
    "# for each combination of occupation and gender, calculate the mean age\n",
    "users.groupby(['occupation', 'gender']).age.mean()\n",
    "\n",
    "# randomly sample a DataFrame\n",
    "import random \n",
    "movie_cols = ['movie_id', 'title']\n",
    "movies = pd.read_table('../labs/Week 1/u.item', sep='|', header=None, names=movie_cols, usecols=[0, 1])\n",
    "random.sample(movies.index, 10)\n",
    "\n",
    "#detect duplicate users\n",
    "users.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#user_cols = ['user_id', 'occupation']\n",
    "#users = pd.read_table('../labs/Week 1/u.user', sep='|', header=None, names=user_cols)\n",
    "#users.groupby(['occupation', 'gender']).age.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
