{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SYD DAT 4 Lab 2 - Visualisation and Regression\n",
    "\n",
    "##Homework - Due 29th April 2016\n",
    "\n",
    "#### Setup\n",
    "* Signup for an AWS account\n",
    " \n",
    "#### Communication\n",
    "* Imagine you are trying to explain to someone what Linear Regression is - but they have no programming/maths experience? How would you explain the overall process, what a p-value means and what R-Squared means?\n",
    "\n",
    "  Linear regression is a technique that is used to predict values of a continuous variable. For example the price of a house will always depend on properties of the house like number of rooms, location, type of house etc.\n",
    "  This technique seeks to model a relationship between the price(dependent variable) and the independent variables(such as number of bedrooms, bathrooms, location).\n",
    "\n",
    "  P-Value is a sort of weight attached to each independent variable, it helps us to determine how much impact a particular independent variable(feature) has on the predicted value. \n",
    "  A P-Value of less than 0.5 means a particular independent variable has a valuable impact on the predicted value, where as a P-Value of greater than 0.5 means that the independent variable does not have much impact on the predicted value.\n",
    "\n",
    "  R-squared is the error, ie, the average of the difference between predicted and actual value, the goal of linear regression is to reduce this value as much as possible.\n",
    "\n",
    "* Read the paper [Useful things to know about machine learning]( https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf). \n",
    "    * What have we covered so far from this paper? \n",
    "    \n",
    "    A model that generalizes well, is better than a model that overfits. One way to ensure that our models generalises well is to split our dataset between training and test set because this helps to see how our model performs with data it has not seen before.\n",
    "    \n",
    "    Other topics that we have covered include Bias Variance, Feature Engineering.\n",
    "    \n",
    "    * Explain sections 6-13 in your own words\n",
    "    \n",
    "    **Feature Selection\n",
    "    \n",
    "    The most important factor in the success of a machine learning algorithm is the features used. Learning is really easy when the features correlate well with the classes.\n",
    "    Sometimes the features may not be in a form that is ready for input into the model and we need to process them into a format that can be input into our models for example a gender column can be encoded into 1 and 0 for male and female respectively.\n",
    "    We need to have a good understanding of the problem domain to be able to come up with good features.\n",
    "    \n",
    "    One thing to note is that, generalizing becomes harder as dimensionality increases. \n",
    "   \n",
    "    **Improving accuracy\n",
    "    \n",
    "    Bagging, boosting, stacking are techniques that we can use to create model emsembles which give us better results. Combining multiple machine learning algorithms produces better results than using just one model, this is what a model emsemble means.\n",
    "    \n",
    "    Bagging enables us to randomly split the training data, so we can try model on different sets of the training data and take average results. This reduces variance.\n",
    "    \n",
    "    With boosting we can attach weights to training examples that we can try different algorithms / models on examples that were wrongly predicted by previous models\n",
    "    \n",
    "    Stacking on the other hand is when the output of one algorithm / model becomes the input of another.\n",
    "    \n",
    "\n",
    "#### Machine Learning\n",
    "* Read chapters 3 and 6 of Introduction to Statistical Learning\n",
    "* Describe 3 ways we can select what features to use in a model\n",
    "    * Regularization\n",
    "    * We can also compute p-values for all features to determine which ones actually have an impact on the predicted value.\n",
    "    * Through our knowlegde of the problem domain we might be able to identify what features have a bigger impact on the results of our model than other features.\n",
    "    \n",
    "* Complete the first 3 exercises from Chapter 3 in Python\n",
    "\n",
    "  Exercise 1\n",
    "\n",
    "  Null hypothesis is a way to prove whether there is a relationship between a given independent variable(feature) and the predicted value.\n",
    "  A p-value of less than 0.5 means that there is no relationship so this feature should not be included in our model.   Based on the table 3.4, there is a relationship between between TV and radio on the sales whereas there is none on newspaper advertising.\n",
    "\n",
    "  Exercise 2\n",
    "  \n",
    "  In general the KNN algorithm will identify K training examples that are closest(we can also say k training examples that are most similar) to a given prediction point x.\n",
    "  Apart from the obvious difference that KNN regression and KNN classifier are used for predicting continous and discrete values respectively, the KNN regression predicts a response by computing the sample average response of the K nearest examples where as the KNN classifier predicts a response by voting between the classes of the K training training examples, the class with highest number of votes will be the class for x.\n",
    "  \n",
    "  Exercise 3\n",
    "  a) In my opinion both iii) and iv) are correct, because IQ has a high coefficient, this means an increase in IQ will have a huge impact on the response(salary in this case). \n",
    "  And also because the fact that female student are coded a value of 1 while male students are coded 0 does not necesssarily change the output but its impacts the way we interpret the coefficients.\n",
    "  b) \n",
    "  gpa = 4.0\n",
    "  iq = 110\n",
    "  interaction_between_gpa_and_iq = 110 * 4.0 # value for X4\n",
    "  interaction_between_gpa_and_gender = 4.0   # value for X5\n",
    "  \n",
    "  salary = 50 + (20 * gpa) + (iq * 0.01) + (35 * 1) + (0.01 * interaction_between_gpa_and_iq ) + (interaction_between_gpa_and_gender * -10) \n",
    "  \n",
    "     value of salary is 130.5\n",
    "  \n",
    "  c) True, because the coefficient is a measure of the an increase in the slope with respect to all the other features.\n",
    "  \n",
    "\n",
    "\n",
    "#### Course Project\n",
    "* For the following setup a new github repository for your project and share it with Matt and Ian over Slack.\n",
    "* Load the data you have gathered for your project into Python and run some summary statistics over the data. Are there any interesting features of the data that jump out? (Include the code)\n",
    "* Draft/Sketch on paper (or wireframe) some data visualisations that would be useful for you to explore your data set\n",
    "* Are there any regresion or clustering techniques you could use in your project? Write them down (with the corresponding scikit learn function) and what you think you would get out of it.\n",
    "\n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework2_ian_hansel.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
